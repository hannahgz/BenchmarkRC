{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FullBinaryExampleNotebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP8Hk1nKZ9+HFoZGG6/aiMA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hannahgz/BenchmarkRCStrategies/blob/master/FullBinaryExampleNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es2BnsRc98ZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1119c458-fcf5-4f35-95d3-c9768342cd23"
      },
      "source": [
        "#Get hg19 fasta by download 2bit and then converting to fa\n",
        "![[ -f hg19.2bit ]] || wget http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.2bit -O hg19.2bit  \n",
        "![[ -f twoBitToFa ]] || wget http://hgdownload.soe.ucsc.edu/admin/exe/linux.x86_64/twoBitToFa -O twoBitToFa\n",
        "!chmod a+x twoBitToFa\n",
        "![[ -f hg19.genome.fa ]] || ./twoBitToFa hg19.2bit hg19.genome.fa"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-26 00:59:11--  http://hgdownload.cse.ucsc.edu/goldenPath/hg19/bigZips/hg19.2bit\n",
            "Resolving hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)... 128.114.119.163\n",
            "Connecting to hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)|128.114.119.163|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 816241703 (778M)\n",
            "Saving to: ‘hg19.2bit’\n",
            "\n",
            "hg19.2bit           100%[===================>] 778.43M  20.9MB/s    in 39s     \n",
            "\n",
            "2021-01-26 00:59:50 (19.9 MB/s) - ‘hg19.2bit’ saved [816241703/816241703]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSAHni67HuN2",
        "outputId": "c744c2d1-b0ac-4a0e-935c-4f54afcd0148"
      },
      "source": [
        "!apt-get install bedtools"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  bedtools\n",
            "0 upgraded, 1 newly installed, 0 to remove and 13 not upgraded.\n",
            "Need to get 577 kB of archives.\n",
            "After this operation, 2,040 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 bedtools amd64 2.26.0+dfsg-5 [577 kB]\n",
            "Fetched 577 kB in 2s (300 kB/s)\n",
            "Selecting previously unselected package bedtools.\n",
            "(Reading database ... 146374 files and directories currently installed.)\n",
            "Preparing to unpack .../bedtools_2.26.0+dfsg-5_amd64.deb ...\n",
            "Unpacking bedtools (2.26.0+dfsg-5) ...\n",
            "Setting up bedtools (2.26.0+dfsg-5) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vywmgA09-TM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "215d173b-8d89-4fa7-f90c-a24b788cf918"
      },
      "source": [
        "import gzip\n",
        "![[ -f SPI1_foreground.bed.gz ]] || wget http://mitra.stanford.edu/kundaje/avanti/rc_data/backup_revcomppaperdata/Gm12878/for_henry/tf_data/Spi1/foreground.bed.gz -O SPI1_foreground.bed.gz\n",
        "\n",
        "#only want the first 3 columns of the bed file which include chromosome and peak location\n",
        "![[ -f SPI1_foreground_actual.bed.gz ]] || zcat SPI1_foreground.bed.gz | perl -lane 'print $F[0].\"\\t\".$F[1].\"\\t\".$F[2]' | sortBed | gzip -c > SPI1_foreground_actual.bed.gz\n",
        "#training set consists of all regions except those on chr1 and chr2\n",
        "![[ -f SPI1_foreground_train.bed.gz ]] || zcat SPI1_foreground_actual.bed.gz | egrep -w -v 'chr1|chr2' | gzip -c > SPI1_foreground_train.bed.gz\n",
        "#validation set consists of all regions on chr1\n",
        "![[ -f SPI1_foreground_val.bed.gz ]] || zcat SPI1_foreground_actual.bed.gz | egrep -w 'chr1' | gzip -c > SPI1_foreground_val.bed.gz\n",
        "#test set consists of all regions on chr2\n",
        "![[ -f SPI1_foreground_test.bed.gz ]] || zcat SPI1_foreground_actual.bed.gz | egrep -w 'chr2' | gzip -c > SPI1_foreground_test.bed.gz"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-26 00:48:48--  http://mitra.stanford.edu/kundaje/avanti/rc_data/backup_revcomppaperdata/Gm12878/for_henry/tf_data/Spi1/foreground.bed.gz\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 867245 (847K) [application/x-gzip]\n",
            "Saving to: ‘SPI1_foreground.bed.gz’\n",
            "\n",
            "SPI1_foreground.bed 100%[===================>] 846.92K  1.21MB/s    in 0.7s    \n",
            "\n",
            "2021-01-26 00:48:49 (1.21 MB/s) - ‘SPI1_foreground.bed.gz’ saved [867245/867245]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDFQIYhn3dlK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17999ee2-e312-4bf0-e3c9-fbc0bc9928e2"
      },
      "source": [
        "#do the same for the background file\n",
        "![[ -f SPI1_background.bed.gz ]] || wget http://mitra.stanford.edu/kundaje/avanti/rc_data/backup_revcomppaperdata/Gm12878/for_henry/tf_data/Spi1/background.bed.gz -O SPI1_background.bed.gz\n",
        "\n",
        "![[ -f SPI1_background_actual.bed.gz ]] || zcat SPI1_background.bed.gz | perl -lane 'print $F[0].\"\\t\".$F[1].\"\\t\".$F[2]' | sortBed | gzip -c > SPI1_background_actual.bed.gz\n",
        "#train set\n",
        "![[ -f SPI1_background_train.bed.gz ]] || zcat SPI1_background_actual.bed.gz | egrep -w -v 'chr1|chr2' | gzip -c > SPI1_background_train.bed.gz\n",
        "#validation set\n",
        "![[ -f SPI1_background_val.bed.gz ]] || zcat SPI1_background_actual.bed.gz | egrep -w 'chr1' | gzip -c > SPI1_background_val.bed.gz\n",
        "#test set\n",
        "![[ -f SPI1_background_test.bed.gz ]] || zcat SPI1_background_actual.bed.gz | egrep -w 'chr2' | gzip -c > SPI1_background_test.bed.gz"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-26 00:48:55--  http://mitra.stanford.edu/kundaje/avanti/rc_data/backup_revcomppaperdata/Gm12878/for_henry/tf_data/Spi1/background.bed.gz\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3784041 (3.6M) [application/x-gzip]\n",
            "Saving to: ‘SPI1_background.bed.gz’\n",
            "\n",
            "SPI1_background.bed 100%[===================>]   3.61M  3.34MB/s    in 1.1s    \n",
            "\n",
            "2021-01-26 00:48:56 (3.34 MB/s) - ‘SPI1_background.bed.gz’ saved [3784041/3784041]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h38UXj5M6fza",
        "outputId": "2cb419fa-1d7e-42db-be73-fa6cc69c92d4"
      },
      "source": [
        "!zcat SPI1_foreground.bed.gz | head"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chr17\t66493802\t66494802\tidrChipSeqPeaks\tchr17:66494123-66494471\n",
            "chr11\t117881374\t117882374\tidrChipSeqPeaks\tchr11:117881603-117882133\n",
            "chr1\t192577938\t192578938\tidrChipSeqPeaks\tchr1:192578265-192578639\n",
            "chr12\t24858378\t24859378\tidrChipSeqPeaks\tchr12:24858665-24859058\n",
            "chr19\t35695893\t35696893\tidrChipSeqPeaks\tchr19:35696206-35696655\n",
            "chr13\t53495039\t53496039\tidrChipSeqPeaks\tchr13:53495355-53495776\n",
            "chr2\t60666201\t60667201\tidrChipSeqPeaks\tchr2:60666502-60666880\n",
            "chr18\t3177598\t3178598\tidrChipSeqPeaks\tchr18:3177902-3178305\n",
            "chr14\t68734604\t68735604\tidrChipSeqPeaks\tchr14:68734937-68735268\n",
            "chr9\t126964391\t126965391\tidrChipSeqPeaks\tchr9:126964700-126965152\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXvFZ7co7qz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea90eab-fe54-4f50-a01e-5db26455d54f"
      },
      "source": [
        "!zcat SPI1_foreground_val.bed.gz | head"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chr1\t839625\t840625\n",
            "chr1\t841786\t842786\n",
            "chr1\t937248\t938248\n",
            "chr1\t961668\t962668\n",
            "chr1\t970836\t971836\n",
            "chr1\t973753\t974753\n",
            "chr1\t999369\t1000369\n",
            "chr1\t1079129\t1080129\n",
            "chr1\t1147949\t1148949\n",
            "chr1\t1166399\t1167399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vjwimle36BAc"
      },
      "source": [
        "#create lookup file, concatenating 1 to the end of foreground file for the pos bed file\n",
        "#concatenate 0 to the end of the background file for the neg bed file\n",
        "![[ -f SPI1_foreground_lookup.bed.gz ]] || zcat SPI1_foreground.bed.gz | perl -lane 'print $F[0].\"\\t\".$F[1].\"\\t\".$F[2].\"\\t\".1' |  gzip -c > SPI1_foreground_lookup.bed.gz\n",
        "![[ -f SPI1_background_lookup.bed.gz ]] || zcat SPI1_background.bed.gz | perl -lane 'print $F[0].\"\\t\".$F[1].\"\\t\".$F[2].\"\\t\".0' | gzip -c > SPI1_background_lookup.bed.gz\n",
        "!cat SPI1_foreground_lookup.bed.gz SPI1_background_lookup.bed.gz > SPI1_lookup.bed.gz"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXDoPaJ950-g",
        "outputId": "9ebe5fac-40bc-4b59-9c00-0444581ed165"
      },
      "source": [
        "!zcat SPI1_lookup.bed.gz | head"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chr17\t66493802\t66494802\t1\n",
            "chr11\t117881374\t117882374\t1\n",
            "chr1\t192577938\t192578938\t1\n",
            "chr12\t24858378\t24859378\t1\n",
            "chr19\t35695893\t35696893\t1\n",
            "chr13\t53495039\t53496039\t1\n",
            "chr2\t60666201\t60667201\t1\n",
            "chr18\t3177598\t3178598\t1\n",
            "chr14\t68734604\t68735604\t1\n",
            "chr9\t126964391\t126965391\t1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YcwJDNj39n7",
        "outputId": "7cfcd874-b366-4ca6-f75e-a10eb57adafe"
      },
      "source": [
        "!wget http://mitra.stanford.edu/kundaje/avanti/rc_data/backup_revcomppaperdata/Gm12878/Spi1/valid_data.hdf5\n",
        "!wget http://mitra.stanford.edu/kundaje/avanti/rc_data/backup_revcomppaperdata/Gm12878/Spi1/test_data.hdf5"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-26 03:35:00--  http://mitra.stanford.edu/kundaje/avanti/rc_data/backup_revcomppaperdata/Gm12878/Spi1/valid_data.hdf5\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16421649 (16M)\n",
            "Saving to: ‘valid_data.hdf5’\n",
            "\n",
            "valid_data.hdf5     100%[===================>]  15.66M  9.56MB/s    in 1.6s    \n",
            "\n",
            "2021-01-26 03:35:02 (9.56 MB/s) - ‘valid_data.hdf5’ saved [16421649/16421649]\n",
            "\n",
            "--2021-01-26 03:35:02--  http://mitra.stanford.edu/kundaje/avanti/rc_data/backup_revcomppaperdata/Gm12878/Spi1/test_data.hdf5\n",
            "Resolving mitra.stanford.edu (mitra.stanford.edu)... 171.67.96.243\n",
            "Connecting to mitra.stanford.edu (mitra.stanford.edu)|171.67.96.243|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13756995 (13M)\n",
            "Saving to: ‘test_data.hdf5’\n",
            "\n",
            "test_data.hdf5      100%[===================>]  13.12M  8.80MB/s    in 1.5s    \n",
            "\n",
            "2021-01-26 03:35:04 (8.80 MB/s) - ‘test_data.hdf5’ saved [13756995/13756995]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8-MR_Dq4xk6",
        "outputId": "5840446c-f950-4bb6-e0e9-d9372b1627f0"
      },
      "source": [
        "!pip install momma_dragonn"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: momma_dragonn in /usr/local/lib/python3.6/dist-packages (0.2.7.0)\n",
            "Requirement already satisfied: avutils in /usr/local/lib/python3.6/dist-packages (from momma_dragonn) (0.2.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from momma_dragonn) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf045kHKRdlN",
        "outputId": "691e8ca6-e8b1-4610-820d-510bd167ae5e"
      },
      "source": [
        "import momma_dragonn\n",
        "\n",
        "valid_data_loader = momma_dragonn.data_loaders.hdf5_data_loader.MultimodalAtOnceDataLoader(\n",
        "    path_to_hdf5=\"valid_data.hdf5\", strip_enclosing_dictionary=True)\n",
        "valid_data = valid_data_loader.get_data()\n",
        "    \n",
        "test_data_loader = momma_dragonn.data_loaders.hdf5_data_loader.MultimodalAtOnceDataLoader(\n",
        "    path_to_hdf5=\"test_data.hdf5\", strip_enclosing_dictionary=True)\n",
        "test_data = test_data_loader.get_data()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/momma_dragonn/data_loaders/hdf5_data_loader.py:32: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  self.f = h5py.File(self.path_to_hdf5)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Input modes ['sequence']\n",
            "Output modes ['output']\n",
            "Input modes ['sequence']\n",
            "Output modes ['output']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-mKIPVPOE5U"
      },
      "source": [
        "Coordinates = namedtuple(\"Coordinates\",\n",
        "                         [\"chrom\", \"start\", \"end\", \"isplusstrand\"])\n",
        "Coordinates.__new__.__defaults__ = (True,)\n",
        "\n",
        "\n",
        "def apply_mask(tomask, mask):\n",
        "    if isinstance(tomask, dict):\n",
        "        return dict([(key, val[mask]) for key,val in tomask.items()])\n",
        "    elif isinstance(tomask, list):\n",
        "        return [x[mask] for x in mask]\n",
        "    else:\n",
        "        return x[mask]\n",
        "\n",
        "\n",
        "class KerasBatchGenerator(keras.utils.Sequence):\n",
        "  \n",
        "    \"\"\"\n",
        "    Args:\n",
        "        coordsbatch_producer (KerasSequenceApiCoordsBatchProducer)\n",
        "        inputs_coordstovals (CoordsToVals)\n",
        "        targets_coordstovals (CoordsToVals)\n",
        "        sampleweights_coordstovals (CoordsToVals)\n",
        "        coordsbatch_transformer (AbstracCoordBatchTransformer)\n",
        "        qc_func (callable): function that can be used to filter\n",
        "            out poor-quality sequences.\n",
        "        sampleweights_coordstoval: either this argument or\n",
        "            sampleweights_from_inputstargets could be used to\n",
        "            specify sample weights. sampleweights_coordstoval\n",
        "            takes a batch of coords as inputs.\n",
        "        sampleweights_from_inputstargets: either this argument or\n",
        "            sampleweights_coordstoval could be used to\n",
        "            specify sample weights. sampleweights_from_inputstargets\n",
        "            takes the inputs and targets values to generate the weights.\n",
        "    \"\"\"\n",
        "    def __init__(self, coordsbatch_producer,\n",
        "                       inputs_coordstovals,\n",
        "                       targets_coordstovals,\n",
        "                       coordsbatch_transformer=None,\n",
        "                       qc_func=None,\n",
        "                       sampleweights_coordstovals=None,\n",
        "                       sampleweights_from_inputstargets=None):\n",
        "        self.coordsbatch_producer = coordsbatch_producer\n",
        "        self.inputs_coordstovals = inputs_coordstovals\n",
        "        self.targets_coordstovals = targets_coordstovals\n",
        "        self.coordsbatch_transformer = coordsbatch_transformer\n",
        "        self.sampleweights_coordstovals = sampleweights_coordstovals\n",
        "        self.sampleweights_from_inputstargets =\\\n",
        "            sampleweights_from_inputstargets\n",
        "        if sampleweights_coordstovals is not None:\n",
        "            assert sampleweights_from_inputstargets is None\n",
        "        if sampleweights_from_inputstargets is not None:\n",
        "            assert sampleweights_coordstovals is None\n",
        "        self.qc_func = qc_func\n",
        " \n",
        "    def __getitem__(self, index):\n",
        "        coords_batch = self.coordsbatch_producer[index]\n",
        "        if (self.coordsbatch_transformer is not None):\n",
        "            coords_batch = self.coordsbatch_transformer(coords_batch)\n",
        "        inputs = self.inputs_coordstovals(coords_batch)\n",
        "        if (self.targets_coordstovals is not None):\n",
        "            targets = self.targets_coordstovals(coords_batch)\n",
        "        else:\n",
        "            targets=None\n",
        "        if (self.qc_func is not None):\n",
        "            qc_mask = self.qc_func(inputs=inputs, targets=targets)\n",
        "            inputs = apply_mask(tomask=inputs, mask=qc_mask)\n",
        "            if (targets is not None):\n",
        "                targets = apply_mask(tomask=targets, mask=qc_mask)\n",
        "        else:\n",
        "            qc_mask = None\n",
        "        if (self.sampleweights_coordstovals is not None):\n",
        "            sample_weights = self.sampleweights_coordstovals(coords_batch)\n",
        "            return (inputs, targets, sample_weights)\n",
        "        elif (self.sampleweights_from_inputstargets is not None):\n",
        "            sample_weights = self.sampleweights_from_inputstargets(\n",
        "                                inputs=inputs, targets=targets)\n",
        "            return (inputs, targets, sample_weights)\n",
        "        else:\n",
        "            if (self.targets_coordstovals is not None):\n",
        "                return (inputs, targets)\n",
        "            else:\n",
        "                return inputs\n",
        "   \n",
        "    def __len__(self):\n",
        "        return len(self.coordsbatch_producer)\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        self.coordsbatch_producer.on_epoch_end()\n",
        "        \n",
        "        \n",
        "def get_new_coors_around_center(coors, center_size_to_use):\n",
        "    new_coors = []\n",
        "    for coor in coors:\n",
        "        coor_center = int(0.5*(coor.start + coor.end))\n",
        "        left_flank = int(0.5*center_size_to_use)\n",
        "        right_flank = center_size_to_use - left_flank\n",
        "        new_start = coor_center-left_flank\n",
        "        new_end = coor_center+right_flank\n",
        "        new_coors.append(Coordinates(chrom=coor.chrom,\n",
        "                                     start=new_start, end=new_end,\n",
        "                                     isplusstrand=coor.isplusstrand))\n",
        "    return new_coors\n",
        "\n",
        "\n",
        "class CoordsToVals(object):\n",
        "    \n",
        "    def __call__(self, coors):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            coors (:obj:`list` of :obj:`Coordinates`):\n",
        "        Returns:\n",
        "            numpy ndarray OR list of ndarrays OR a dict of mode_name->ndarray.\n",
        "              Returns a list of ndarrays if returning multiple modes.\n",
        "              Alternatively, returns a dict where key is the mode name\n",
        "              and the value is the ndarray for the mode.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "\n",
        "class CoordsToValsJoiner(CoordsToVals):\n",
        "\n",
        "    def __init__(self, coordstovals_list):\n",
        "        \"\"\"\n",
        "        Joins batches returned by other CoordsToVals objects\n",
        "        Args:\n",
        "            coorstovals_list (:obj:`list` of :obj:`CoordsToVals`): List of\n",
        "                CoordsToVals whose values to combine\n",
        "        \"\"\"\n",
        "        self.coordstovals_list = coordstovals_list\n",
        "                \n",
        "    def __call__(self, coors):\n",
        "        batch_to_return = None        \n",
        "        for idx,coordstovals_obj in enumerate(self.coordstovals_list):\n",
        "            the_batch = coordstovals_obj(coors=coors)\n",
        "            assert the_batch is not None\n",
        "            if isinstance(the_batch, dict):\n",
        "                assert ((batch_to_return is None) or\n",
        "                        (isinstance(batch_to_return, dict))), (\n",
        "                        \"coordstovals object at idx\"+str(idx)\n",
        "                        +\" returned a dict, but previous coordstovals\"\n",
        "                        +\" objects had a return type incompatible with this\")\n",
        "                if (batch_to_return is None):\n",
        "                    batch_to_return = {}\n",
        "                for key in the_batch:\n",
        "                    assert key not in batch_to_return, (\n",
        "                      \"coordstovals object at idx\"+str(idx)\n",
        "                      +\" returned a dict with a key of \"+key\n",
        "                      +\", which collides with a pre-existing key returned by\"\n",
        "                      +\" another coordstovals object\")\n",
        "                batch_to_return.update(the_batch)\n",
        "            else:\n",
        "                assert ((batch_to_return is None) or\n",
        "                        (isinstance(batch_to_return, list))), (\n",
        "                        \"coordstovals object at idx\"+str(idx)\n",
        "                        +\" returned a type incompatible with dict, but previous\"\n",
        "                        +\" coordstovals objects had a return type of dict\")\n",
        "                if (isinstance(the_batch, list)==False):\n",
        "                    the_batch = [the_batch]\n",
        "                if (batch_to_return is None):\n",
        "                    batch_to_return = []\n",
        "                batch_to_return.extend(the_batch)\n",
        "        if (batch_to_return is None):\n",
        "            batch_to_return = []\n",
        "        return batch_to_return\n",
        "\n",
        "\n",
        "class AbstractSingleNdarrayCoordsToVals(CoordsToVals):\n",
        "\n",
        "    def __init__(self, mode_name=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            mode_name (:obj:`str`, optional): default None. If None, then\n",
        "                the return of __call__ will be a numpy ndarray. Otherwise, it\n",
        "                will be a dictionary with a key of mode_name and a value being\n",
        "                the numpy ndarray.\n",
        "        \"\"\"\n",
        "        self.mode_name = mode_name\n",
        "    \n",
        "    def _get_ndarray(self, coors):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            coors (:obj:`list` of :obj:`Coordinates):\n",
        "            \n",
        "        Returns:\n",
        "            numpy ndarray\n",
        "        \"\"\"\n",
        "        raise NotImplementedError()\n",
        "    \n",
        "    def __call__(self, coors):\n",
        "        ndarray = self._get_ndarray(coors)\n",
        "        if (self.mode_name is None):\n",
        "            return ndarray\n",
        "        else:\n",
        "            return {self.mode_name: ndarray}\n",
        "        \n",
        "        \n",
        "class SimpleLookup(AbstractSingleNdarrayCoordsToVals):\n",
        "\n",
        "    def __init__(self, lookup_file,\n",
        "                       transformation=None,\n",
        "                       default_returnval=0.0, **kwargs):\n",
        "        super(SimpleLookup, self).__init__(**kwargs)\n",
        "        self.lookup_file = lookup_file\n",
        "        self.transformation = transformation\n",
        "        self.default_returnval = default_returnval\n",
        "        self.lookup = {}\n",
        "        self.num_labels = None\n",
        "        for line in (gzip.open(self.lookup_file) if \".gz\"\n",
        "                     in self.lookup_file else open(self.lookup_file)):\n",
        "            (chrom, start_str, end_str, *labels) =\\\n",
        "              line.decode(\"utf-8\").rstrip().split(\"\\t\")\n",
        "            coord = Coordinates(chrom=chrom,\n",
        "                                start=int(start_str),\n",
        "                                end=int(end_str))\n",
        "            labels = [(self.transformation(float(x))\n",
        "                       if self.transformation is not None else float(x))\n",
        "                      for x in labels] \n",
        "            self.lookup[(coord.chrom, coord.start, coord.end)] = labels\n",
        "            if (self.num_labels is None):\n",
        "                self.num_labels = len(labels)\n",
        "            else:\n",
        "                assert len(labels)==self.num_labels,(\n",
        "                  \"Unequal label lengths; \"+str(len(labels), self.num_labels))\n",
        "    \n",
        "    def _get_ndarray(self, coors):\n",
        "        to_return = []\n",
        "        for coor in coors:\n",
        "            if (coor.chrom, coor.start, coor.end) not in self.lookup:\n",
        "                to_return.append(np.ones(self.num_labels)\n",
        "                                 *self.default_returnval)\n",
        "            else:\n",
        "                to_return.append(\n",
        "                    self.lookup[(coor.chrom, coor.start, coor.end)])\n",
        "        return np.array(to_return)\n",
        "\n",
        "def get_generators(dataset, seq_len, is_aug, curr_seed): \n",
        "    inputs_coordstovals = coordbased.coordstovals.fasta.PyfaidxCoordsToVals(\n",
        "        genome_fasta_path=\"hg19.genome.fa\",\n",
        "        center_size_to_use= seq_len)\n",
        "    \n",
        "    targets_coordstovals = SimpleLookup(\n",
        "        lookup_file = \"SPI1_lookup.bed.gz\",\n",
        "        transformation = None, default_returnval = 0.0) \n",
        "\n",
        "    target_proportion_positives = 1/5\n",
        "    \n",
        "    if not is_aug: \n",
        "        standard_train_batch_generator = KerasBatchGenerator(\n",
        "          coordsbatch_producer=coordbatchproducers.DownsampleNegativesCoordsBatchProducer(\n",
        "              pos_bed_file = \"SPI1_foreground_train.bed.gz\",\n",
        "              neg_bed_file = \"SPI1_background_train.bed.gz\",\n",
        "              target_proportion_positives = target_proportion_positives, \n",
        "              batch_size=100,\n",
        "              shuffle_before_epoch=True, \n",
        "              seed=curr_seed),\n",
        "          inputs_coordstovals=inputs_coordstovals,\n",
        "          targets_coordstovals=targets_coordstovals)\n",
        "        return standard_train_batch_generator\n",
        "    else: \n",
        "        aug_train_batch_generator = KerasBatchGenerator(\n",
        "          coordsbatch_producer=coordbatchproducers.DownsampleNegativesCoordsBatchProducer(\n",
        "              pos_bed_file = \"SPI1_foreground_train.bed.gz\",\n",
        "              neg_bed_file = \"SPI1_background_train.bed.gz\",\n",
        "              target_proportion_positives = target_proportion_positives, \n",
        "              batch_size=100,\n",
        "              shuffle_before_epoch=True, \n",
        "              seed=curr_seed),\n",
        "          inputs_coordstovals=inputs_coordstovals,\n",
        "          targets_coordstovals=targets_coordstovals,\n",
        "          coordsbatch_transformer=coordbatchtransformers.ReverseComplementAugmenter())\n",
        "        return aug_train_batch_generator"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivGwFhQvDZFN",
        "outputId": "ff5a5171-512c-4b68-8f8c-c22ac8a0e148"
      },
      "source": [
        "!pip install keras-genomics\n",
        "!pip install seqdataloader\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from seqdataloader.batchproducers import coordbased\n",
        "from seqdataloader.batchproducers.coordbased import coordstovals\n",
        "from seqdataloader.batchproducers.coordbased import coordbatchproducers\n",
        "from seqdataloader.batchproducers.coordbased import coordbatchtransformers\n",
        "from seqdataloader.batchproducers.coordbased.coordbatchproducers import DownsampleNegativesCoordsBatchProducer\n",
        "from seqdataloader.batchproducers.coordbased.coordbatchproducers import SimpleCoordsBatchProducer\n",
        "from seqdataloader.batchproducers.coordbased.coordstovals.bigwig import AbstractCountAndProfileTransformer \n",
        "from seqdataloader.batchproducers.coordbased.coordstovals.bigwig import LogCountsPlusOne\n",
        "from seqdataloader.batchproducers.coordbased.coordstovals.bigwig import SmoothProfiles\n",
        "from seqdataloader.batchproducers.coordbased.coordstovals.bigwig import BigWigReader \n",
        "from seqdataloader.batchproducers.coordbased.coordstovals.bigwig import smooth_profiles\n",
        "from seqdataloader.batchproducers.coordbased.coordstovals.bigwig import rolling_window\n",
        "from seqdataloader.batchproducers.coordbased.core import Coordinates, KerasBatchGenerator, apply_mask\n",
        "from seqdataloader.batchproducers.coordbased.coordbatchtransformers import AbstractCoordBatchTransformer\n",
        "from seqdataloader.batchproducers.coordbased.coordbatchtransformers import get_revcomp\n",
        "import numpy as np\n",
        "\n",
        "import os"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-genomics in /usr/local/lib/python3.6/dist-packages (0.1.2.1)\n",
            "Requirement already satisfied: keras in /tensorflow-1.15.2/python3.6 (from keras-genomics) (2.3.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /tensorflow-1.15.2/python3.6 (from keras->keras-genomics) (1.0.8)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras->keras-genomics) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras->keras-genomics) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras->keras-genomics) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras->keras-genomics) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras->keras-genomics) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras->keras-genomics) (1.15.0)\n",
            "Requirement already satisfied: seqdataloader in /usr/local/lib/python3.6/dist-packages (1.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.6/dist-packages (from seqdataloader) (1.1.5)\n",
            "Requirement already satisfied: pybedtools>=0.7 in /usr/local/lib/python3.6/dist-packages (from seqdataloader) (0.8.1)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from seqdataloader) (0.29.21)\n",
            "Requirement already satisfied: pyfaidx in /usr/local/lib/python3.6/dist-packages (from seqdataloader) (0.5.9.2)\n",
            "Requirement already satisfied: pyBigWig>=0.3.7 in /usr/local/lib/python3.6/dist-packages (from seqdataloader) (0.3.17)\n",
            "Requirement already satisfied: deeptools>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from seqdataloader) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seqdataloader) (1.19.5)\n",
            "Requirement already satisfied: tiledb>=0.4.4 in /usr/local/lib/python3.6/dist-packages (from seqdataloader) (0.7.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->seqdataloader) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.4->seqdataloader) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pybedtools>=0.7->seqdataloader) (1.15.0)\n",
            "Requirement already satisfied: pysam in /usr/local/lib/python3.6/dist-packages (from pybedtools>=0.7->seqdataloader) (0.16.0.1)\n",
            "Requirement already satisfied: setuptools>=0.7 in /usr/local/lib/python3.6/dist-packages (from pyfaidx->seqdataloader) (51.3.3)\n",
            "Requirement already satisfied: plotly>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader) (4.4.1)\n",
            "Requirement already satisfied: py2bit>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader) (0.3.0)\n",
            "Requirement already satisfied: numpydoc>=0.5 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader) (1.1.0)\n",
            "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader) (3.2.2)\n",
            "Requirement already satisfied: deeptoolsintervals>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader) (0.1.9)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from deeptools>=3.0.1->seqdataloader) (1.4.1)\n",
            "Requirement already satisfied: wheel>=0.30 in /usr/local/lib/python3.6/dist-packages (from tiledb>=0.4.4->seqdataloader) (0.36.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=2.0.0->deeptools>=3.0.1->seqdataloader) (1.3.3)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (2.11.2)\n",
            "Requirement already satisfied: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (1.8.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->deeptools>=3.0.1->seqdataloader) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->deeptools>=3.0.1->seqdataloader) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->deeptools>=3.0.1->seqdataloader) (2.4.7)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (1.1.1)\n",
            "Requirement already satisfied: docutils>=0.11 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (0.16)\n",
            "Requirement already satisfied: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (1.2.4)\n",
            "Requirement already satisfied: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (2.9.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (20.8)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (2.6.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (0.7.12)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (2.0.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.6/dist-packages (from sphinxcontrib-websupport->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (1.1.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->sphinx>=1.6.5->numpydoc>=0.5->deeptools>=3.0.1->seqdataloader) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAAN_Q_YL1dS"
      },
      "source": [
        "from keras import backend as K \n",
        "from keras.layers.core import Dropout \n",
        "from keras.layers.core import Flatten\n",
        "from keras.engine import Layer\n",
        "from keras.models import Sequential \n",
        "import keras.layers as kl\n",
        "from keras.engine.base_layer import InputSpec\n",
        "from keras_genomics.layers import RevCompConv1D\n",
        "from keras import initializers"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "194PCA87LkPl"
      },
      "source": [
        "def get_reg_model(parameters):\n",
        "    model = keras.models.Sequential()\n",
        "    model.add(keras.layers.Convolution1D(\n",
        "              input_shape=(1000,4), nb_filter=16, filter_length=15))\n",
        "    model.add(keras.layers.normalization.BatchNormalization())\n",
        "    model.add(keras.layers.core.Activation(\"relu\"))\n",
        "    model.add(keras.layers.convolutional.Convolution1D(\n",
        "            nb_filter=16, filter_length=14))\n",
        "    model.add(keras.layers.normalization.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"relu\"))\n",
        "    model.add(keras.layers.convolutional.Convolution1D(\n",
        "            nb_filter=16, filter_length=14))\n",
        "    model.add(keras.layers.normalization.BatchNormalization())\n",
        "    model.add(keras.layers.Activation(\"relu\"))\n",
        "    model.add(keras.layers.convolutional.MaxPooling1D(pool_length=parameters['pool_size'],\n",
        "                                                      strides= parameters['strides']))         \n",
        "    model.add(Flatten())\n",
        "    model.add(keras.layers.core.Dense(output_dim=1, trainable=True,\n",
        "                                    init=\"glorot_uniform\"))\n",
        "    model.add(keras.layers.core.Activation(\"sigmoid\"))\n",
        "    model.compile(optimizer = keras.optimizers.Adam(lr=0.001), \n",
        "                  loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "    return model"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw3D7uqwDUOn",
        "outputId": "cd1e05d9-a5c3-45ba-c0ef-0f7861f7dd0e"
      },
      "source": [
        "parameters = {\n",
        "    'filters': 16, \n",
        "    'input_length':1000, \n",
        "    'pool_size':40, \n",
        "    'strides': 20\n",
        "}\n",
        "\n",
        "model = get_reg_model(parameters)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(input_shape=(1000, 4), filters=16, kernel_size=15)`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=16, kernel_size=14)`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=16, kernel_size=14)`\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `MaxPooling1D` call to the Keras 2 API: `MaxPooling1D(strides=20, pool_size=40)`\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(trainable=True, units=1, kernel_initializer=\"glorot_uniform\")`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gglRZdUrMPXo",
        "outputId": "acbddf6f-3aff-428d-91cd-5bac0a74a371"
      },
      "source": [
        "epochs_to_train_for = 160 \n",
        "standard_train_batch_generator = get_generators(dataset = \"SPI1\", \n",
        "                                                seq_len = 1000, \n",
        "                                                curr_seed = 1234, \n",
        "                                                is_aug = False)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading in positive bed file\n",
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Got 35276  coords in positive bed file\n",
            "Reading in negative bed file\n",
            "Heads up: coordinates in bed file are assumed to be on the positive strand; if strand in the bed file is improtant to you, please add that feature to SimpleCoordsBatchProducer\n",
            "Got 182577  coords in negative bed file\n",
            "The target proportion of positives of 0.2 requires the negative set to be subsampled by a factor of 2 which will result in a #neg of 91288\n",
            "Using an offset of  0  before striding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTqRgfirLueS"
      },
      "source": [
        "from keras.callbacks import History\n",
        "\n",
        "class AuRocCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, model, valid_X, valid_Y):\n",
        "        self.model = model\n",
        "        self.valid_X = valid_X\n",
        "        self.valid_Y = valid_Y\n",
        "        self.best_auroc_sofar = 0.0\n",
        "        self.best_weights = None\n",
        "        self.best_epoch_number = 0\n",
        "    def on_epoch_end(self, epoch, logs):\n",
        "        preds = self.model.predict(self.valid_X)\n",
        "        auroc = roc_auc_score(y_true=self.valid_Y, y_score=preds)\n",
        "        if (auroc > self.best_auroc_sofar):\n",
        "            self.best_weights = self.model.get_weights()\n",
        "            self.best_epoch_number = epoch\n",
        "            self.best_auroc_sofar = auroc\n",
        "\n",
        "def train_model(model, curr_seed, train_data_loader, batch_generator,\n",
        "                valid_data, epochs_to_train_for, upsampling):\n",
        "\n",
        "    np.random.seed(curr_seed)\n",
        "    tf.set_random_seed(curr_seed)\n",
        "    \n",
        "    if upsampling == False:\n",
        "        early_stopping_callback = keras.callbacks.EarlyStopping(\n",
        "                                  monitor='val_loss',\n",
        "                                  patience=epochs_to_train_for,\n",
        "                                  restore_best_weights=True)\n",
        "\n",
        "        auroc_callback = AuRocCallback(model = model,\n",
        "                                       valid_X=valid_data.X,\n",
        "                                       valid_Y=valid_data.Y)\n",
        "        history = History()\n",
        "        loss_history = model.fit_generator(train_data_loader.get_batch_generator(),\n",
        "                                           validation_data = (valid_data.X, valid_data.Y),\n",
        "                                           epochs=epochs_to_train_for,\n",
        "                                           steps_per_epoch=50,\n",
        "                                           class_weight={0:1, 1: 4.75},\n",
        "                                           callbacks=[auroc_callback, early_stopping_callback, history])\n",
        "        return early_stopping_callback, auroc_callback, history, model\n",
        "    else: \n",
        "        auroc_callback = AuRocCallback(model = model,\n",
        "                                       valid_X=valid_data.X,\n",
        "                                       valid_Y=valid_data.Y)\n",
        "        history = History()\n",
        "        loss_history = model.fit_generator(batch_generator,\n",
        "                                           validation_data = (valid_data.X, valid_data.Y),\n",
        "                                           epochs=epochs_to_train_for,\n",
        "                                           steps_per_epoch=50,\n",
        "                                           callbacks=[auroc_callback, history])\n",
        "        return auroc_callback, history, model"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAkXUDJFMKsy",
        "outputId": "92d7ba9e-9f02-412b-bd9b-1d2f51de18cf"
      },
      "source": [
        "auroc_callback, history, model = train_model(model = model, \n",
        "                                             curr_seed = 1234, \n",
        "                                             train_data_loader = None,\n",
        "                                             batch_generator = standard_train_batch_generator,\n",
        "                                             valid_data = valid_data, \n",
        "                                             epochs_to_train_for = epochs_to_train_for, \n",
        "                                             upsampling = True)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/160\n",
            "50/50 [==============================] - 38s 765ms/step - loss: 0.7027 - accuracy: 0.6634 - val_loss: 0.6509 - val_accuracy: 0.7260\n",
            "Epoch 2/160\n",
            "50/50 [==============================] - 37s 743ms/step - loss: 0.6173 - accuracy: 0.7022 - val_loss: 0.6044 - val_accuracy: 0.7454\n",
            "Epoch 3/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.6113 - accuracy: 0.7042 - val_loss: 0.5765 - val_accuracy: 0.7458\n",
            "Epoch 4/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.5852 - accuracy: 0.7150 - val_loss: 0.5486 - val_accuracy: 0.7491\n",
            "Epoch 5/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.5345 - accuracy: 0.7448 - val_loss: 0.5139 - val_accuracy: 0.7892\n",
            "Epoch 6/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.4506 - accuracy: 0.7976 - val_loss: 0.4506 - val_accuracy: 0.8349\n",
            "Epoch 7/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.3800 - accuracy: 0.8424 - val_loss: 0.3456 - val_accuracy: 0.8772\n",
            "Epoch 8/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.3023 - accuracy: 0.8762 - val_loss: 0.3147 - val_accuracy: 0.8880\n",
            "Epoch 9/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.2779 - accuracy: 0.8848 - val_loss: 0.2698 - val_accuracy: 0.9009\n",
            "Epoch 10/160\n",
            "50/50 [==============================] - 36s 725ms/step - loss: 0.2571 - accuracy: 0.8962 - val_loss: 0.2475 - val_accuracy: 0.9089\n",
            "Epoch 11/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.2450 - accuracy: 0.8966 - val_loss: 0.2177 - val_accuracy: 0.9145\n",
            "Epoch 12/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.2226 - accuracy: 0.9084 - val_loss: 0.2122 - val_accuracy: 0.9172\n",
            "Epoch 13/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.2080 - accuracy: 0.9180 - val_loss: 0.2073 - val_accuracy: 0.9216\n",
            "Epoch 14/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.2059 - accuracy: 0.9210 - val_loss: 0.1942 - val_accuracy: 0.9259\n",
            "Epoch 15/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.2045 - accuracy: 0.9212 - val_loss: 0.1905 - val_accuracy: 0.9280\n",
            "Epoch 16/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.1959 - accuracy: 0.9238 - val_loss: 0.1878 - val_accuracy: 0.9288\n",
            "Epoch 17/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.2013 - accuracy: 0.9184 - val_loss: 0.1856 - val_accuracy: 0.9278\n",
            "Epoch 18/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1930 - accuracy: 0.9264 - val_loss: 0.1863 - val_accuracy: 0.9302\n",
            "Epoch 19/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1903 - accuracy: 0.9274 - val_loss: 0.1738 - val_accuracy: 0.9352\n",
            "Epoch 20/160\n",
            "50/50 [==============================] - 36s 730ms/step - loss: 0.1917 - accuracy: 0.9254 - val_loss: 0.2989 - val_accuracy: 0.8802\n",
            "Epoch 21/160\n",
            "50/50 [==============================] - 37s 744ms/step - loss: 0.1877 - accuracy: 0.9238 - val_loss: 0.1971 - val_accuracy: 0.9235\n",
            "Epoch 22/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1767 - accuracy: 0.9298 - val_loss: 0.1820 - val_accuracy: 0.9299\n",
            "Epoch 23/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1863 - accuracy: 0.9286 - val_loss: 0.1862 - val_accuracy: 0.9300\n",
            "Epoch 24/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1826 - accuracy: 0.9326 - val_loss: 0.1627 - val_accuracy: 0.9382\n",
            "Epoch 25/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1847 - accuracy: 0.9273 - val_loss: 0.1625 - val_accuracy: 0.9360\n",
            "Epoch 26/160\n",
            "15/50 [========>.....................] - ETA: 14s - loss: 0.1973 - accuracy: 0.9200Using an offset of  1  before striding\n",
            "50/50 [==============================] - 37s 735ms/step - loss: 0.1794 - accuracy: 0.9304 - val_loss: 0.1729 - val_accuracy: 0.9317\n",
            "Epoch 27/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1670 - accuracy: 0.9316 - val_loss: 0.1654 - val_accuracy: 0.9377\n",
            "Epoch 28/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1593 - accuracy: 0.9416 - val_loss: 0.1524 - val_accuracy: 0.9415\n",
            "Epoch 29/160\n",
            "50/50 [==============================] - 36s 724ms/step - loss: 0.1634 - accuracy: 0.9372 - val_loss: 0.1552 - val_accuracy: 0.9405\n",
            "Epoch 30/160\n",
            "50/50 [==============================] - 36s 719ms/step - loss: 0.1615 - accuracy: 0.9388 - val_loss: 0.1520 - val_accuracy: 0.9410\n",
            "Epoch 31/160\n",
            "50/50 [==============================] - 36s 722ms/step - loss: 0.1557 - accuracy: 0.9364 - val_loss: 0.1644 - val_accuracy: 0.9361\n",
            "Epoch 32/160\n",
            "50/50 [==============================] - 36s 724ms/step - loss: 0.1645 - accuracy: 0.9374 - val_loss: 0.1549 - val_accuracy: 0.9407\n",
            "Epoch 33/160\n",
            "50/50 [==============================] - 36s 724ms/step - loss: 0.1604 - accuracy: 0.9378 - val_loss: 0.1534 - val_accuracy: 0.9414\n",
            "Epoch 34/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1721 - accuracy: 0.9320 - val_loss: 0.1520 - val_accuracy: 0.9415\n",
            "Epoch 35/160\n",
            "50/50 [==============================] - 36s 730ms/step - loss: 0.1583 - accuracy: 0.9392 - val_loss: 0.1450 - val_accuracy: 0.9454\n",
            "Epoch 36/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1713 - accuracy: 0.9314 - val_loss: 0.1498 - val_accuracy: 0.9424\n",
            "Epoch 37/160\n",
            "50/50 [==============================] - 37s 734ms/step - loss: 0.1652 - accuracy: 0.9342 - val_loss: 0.1751 - val_accuracy: 0.9346\n",
            "Epoch 38/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1662 - accuracy: 0.9392 - val_loss: 0.1549 - val_accuracy: 0.9425\n",
            "Epoch 39/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1702 - accuracy: 0.9384 - val_loss: 0.1603 - val_accuracy: 0.9396\n",
            "Epoch 40/160\n",
            "50/50 [==============================] - 37s 737ms/step - loss: 0.1613 - accuracy: 0.9404 - val_loss: 0.1502 - val_accuracy: 0.9445\n",
            "Epoch 41/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1563 - accuracy: 0.9410 - val_loss: 0.1416 - val_accuracy: 0.9465\n",
            "Epoch 42/160\n",
            "50/50 [==============================] - 36s 730ms/step - loss: 0.1576 - accuracy: 0.9376 - val_loss: 0.1695 - val_accuracy: 0.9366\n",
            "Epoch 43/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1406 - accuracy: 0.9488 - val_loss: 0.1393 - val_accuracy: 0.9484\n",
            "Epoch 44/160\n",
            "50/50 [==============================] - 36s 722ms/step - loss: 0.1555 - accuracy: 0.9404 - val_loss: 0.1907 - val_accuracy: 0.9259\n",
            "Epoch 45/160\n",
            "50/50 [==============================] - 37s 734ms/step - loss: 0.1572 - accuracy: 0.9388 - val_loss: 0.1418 - val_accuracy: 0.9469\n",
            "Epoch 46/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1660 - accuracy: 0.9386 - val_loss: 0.1704 - val_accuracy: 0.9361\n",
            "Epoch 47/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1514 - accuracy: 0.9412 - val_loss: 0.1965 - val_accuracy: 0.9279\n",
            "Epoch 48/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1482 - accuracy: 0.9416 - val_loss: 0.2671 - val_accuracy: 0.8985\n",
            "Epoch 49/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1630 - accuracy: 0.9370 - val_loss: 0.1503 - val_accuracy: 0.9429\n",
            "Epoch 50/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1456 - accuracy: 0.9444 - val_loss: 0.1446 - val_accuracy: 0.9434\n",
            "Epoch 51/160\n",
            "31/50 [=================>............] - ETA: 8s - loss: 0.1600 - accuracy: 0.9406Using an offset of  0  before striding\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1430 - accuracy: 0.9470 - val_loss: 0.1353 - val_accuracy: 0.9494\n",
            "Epoch 52/160\n",
            "50/50 [==============================] - 36s 723ms/step - loss: 0.1372 - accuracy: 0.9482 - val_loss: 0.1407 - val_accuracy: 0.9450\n",
            "Epoch 53/160\n",
            "50/50 [==============================] - 36s 722ms/step - loss: 0.1423 - accuracy: 0.9442 - val_loss: 0.1483 - val_accuracy: 0.9439\n",
            "Epoch 54/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1338 - accuracy: 0.9506 - val_loss: 0.1345 - val_accuracy: 0.9496\n",
            "Epoch 55/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1344 - accuracy: 0.9506 - val_loss: 0.1737 - val_accuracy: 0.9346\n",
            "Epoch 56/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1337 - accuracy: 0.9486 - val_loss: 0.1352 - val_accuracy: 0.9505\n",
            "Epoch 57/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1356 - accuracy: 0.9472 - val_loss: 0.1317 - val_accuracy: 0.9509\n",
            "Epoch 58/160\n",
            "50/50 [==============================] - 36s 725ms/step - loss: 0.1273 - accuracy: 0.9560 - val_loss: 0.1306 - val_accuracy: 0.9503\n",
            "Epoch 59/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1355 - accuracy: 0.9524 - val_loss: 0.1409 - val_accuracy: 0.9460\n",
            "Epoch 60/160\n",
            "50/50 [==============================] - 36s 725ms/step - loss: 0.1493 - accuracy: 0.9436 - val_loss: 0.1306 - val_accuracy: 0.9505\n",
            "Epoch 61/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1391 - accuracy: 0.9438 - val_loss: 0.1329 - val_accuracy: 0.9506\n",
            "Epoch 62/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1466 - accuracy: 0.9442 - val_loss: 0.1394 - val_accuracy: 0.9477\n",
            "Epoch 63/160\n",
            "50/50 [==============================] - 36s 724ms/step - loss: 0.1453 - accuracy: 0.9448 - val_loss: 0.1407 - val_accuracy: 0.9478\n",
            "Epoch 64/160\n",
            "50/50 [==============================] - 37s 735ms/step - loss: 0.1568 - accuracy: 0.9374 - val_loss: 0.1389 - val_accuracy: 0.9500\n",
            "Epoch 65/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1371 - accuracy: 0.9476 - val_loss: 0.1354 - val_accuracy: 0.9503\n",
            "Epoch 66/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1423 - accuracy: 0.9478 - val_loss: 0.1331 - val_accuracy: 0.9516\n",
            "Epoch 67/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1392 - accuracy: 0.9482 - val_loss: 0.1333 - val_accuracy: 0.9479\n",
            "Epoch 68/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1335 - accuracy: 0.9516 - val_loss: 0.1323 - val_accuracy: 0.9517\n",
            "Epoch 69/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1394 - accuracy: 0.9454 - val_loss: 0.1367 - val_accuracy: 0.9491\n",
            "Epoch 70/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1482 - accuracy: 0.9440 - val_loss: 0.1338 - val_accuracy: 0.9496\n",
            "Epoch 71/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1368 - accuracy: 0.9468 - val_loss: 0.1374 - val_accuracy: 0.9470\n",
            "Epoch 72/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1199 - accuracy: 0.9536 - val_loss: 0.1295 - val_accuracy: 0.9508\n",
            "Epoch 73/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1256 - accuracy: 0.9528 - val_loss: 0.1338 - val_accuracy: 0.9510\n",
            "Epoch 74/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1562 - accuracy: 0.9404 - val_loss: 0.1287 - val_accuracy: 0.9517\n",
            "Epoch 75/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1458 - accuracy: 0.9448 - val_loss: 0.1320 - val_accuracy: 0.9493\n",
            "Epoch 76/160\n",
            "47/50 [===========================>..] - ETA: 1s - loss: 0.1434 - accuracy: 0.9479Using an offset of  1  before striding\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1430 - accuracy: 0.9480 - val_loss: 0.1315 - val_accuracy: 0.9507\n",
            "Epoch 77/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1308 - accuracy: 0.9518 - val_loss: 0.1284 - val_accuracy: 0.9515\n",
            "Epoch 78/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1215 - accuracy: 0.9546 - val_loss: 0.1329 - val_accuracy: 0.9497\n",
            "Epoch 79/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1384 - accuracy: 0.9476 - val_loss: 0.1315 - val_accuracy: 0.9512\n",
            "Epoch 80/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1209 - accuracy: 0.9560 - val_loss: 0.1278 - val_accuracy: 0.9511\n",
            "Epoch 81/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1305 - accuracy: 0.9470 - val_loss: 0.1328 - val_accuracy: 0.9499\n",
            "Epoch 82/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1374 - accuracy: 0.9430 - val_loss: 0.1247 - val_accuracy: 0.9544\n",
            "Epoch 83/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1307 - accuracy: 0.9492 - val_loss: 0.1921 - val_accuracy: 0.9288\n",
            "Epoch 84/160\n",
            "50/50 [==============================] - 36s 724ms/step - loss: 0.1247 - accuracy: 0.9518 - val_loss: 0.1706 - val_accuracy: 0.9367\n",
            "Epoch 85/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1380 - accuracy: 0.9474 - val_loss: 0.1392 - val_accuracy: 0.9491\n",
            "Epoch 86/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1443 - accuracy: 0.9480 - val_loss: 0.1292 - val_accuracy: 0.9509\n",
            "Epoch 87/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1423 - accuracy: 0.9458 - val_loss: 0.1281 - val_accuracy: 0.9529\n",
            "Epoch 88/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.1275 - accuracy: 0.9498 - val_loss: 0.1276 - val_accuracy: 0.9538\n",
            "Epoch 89/160\n",
            "50/50 [==============================] - 36s 723ms/step - loss: 0.1348 - accuracy: 0.9506 - val_loss: 0.1288 - val_accuracy: 0.9513\n",
            "Epoch 90/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1422 - accuracy: 0.9482 - val_loss: 0.1340 - val_accuracy: 0.9501\n",
            "Epoch 91/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1266 - accuracy: 0.9520 - val_loss: 0.1266 - val_accuracy: 0.9528\n",
            "Epoch 92/160\n",
            "50/50 [==============================] - 36s 725ms/step - loss: 0.1259 - accuracy: 0.9504 - val_loss: 0.1233 - val_accuracy: 0.9541\n",
            "Epoch 93/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1213 - accuracy: 0.9518 - val_loss: 0.1562 - val_accuracy: 0.9439\n",
            "Epoch 94/160\n",
            "50/50 [==============================] - 36s 725ms/step - loss: 0.1209 - accuracy: 0.9550 - val_loss: 0.1346 - val_accuracy: 0.9488\n",
            "Epoch 95/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1412 - accuracy: 0.9458 - val_loss: 0.1622 - val_accuracy: 0.9411\n",
            "Epoch 96/160\n",
            "50/50 [==============================] - 36s 720ms/step - loss: 0.1340 - accuracy: 0.9470 - val_loss: 0.1335 - val_accuracy: 0.9508\n",
            "Epoch 97/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1345 - accuracy: 0.9510 - val_loss: 0.1346 - val_accuracy: 0.9485\n",
            "Epoch 98/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1210 - accuracy: 0.9522 - val_loss: 0.1428 - val_accuracy: 0.9474\n",
            "Epoch 99/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1269 - accuracy: 0.9530 - val_loss: 0.1298 - val_accuracy: 0.9515\n",
            "Epoch 100/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.1262 - accuracy: 0.9502 - val_loss: 0.1421 - val_accuracy: 0.9455\n",
            "Epoch 101/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1370 - accuracy: 0.9476 - val_loss: 0.1287 - val_accuracy: 0.9515\n",
            "Epoch 102/160\n",
            "13/50 [======>.......................] - ETA: 14s - loss: 0.1206 - accuracy: 0.9569Using an offset of  0  before striding\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1180 - accuracy: 0.9562 - val_loss: 0.1235 - val_accuracy: 0.9539\n",
            "Epoch 103/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1057 - accuracy: 0.9582 - val_loss: 0.1311 - val_accuracy: 0.9495\n",
            "Epoch 104/160\n",
            "50/50 [==============================] - 36s 725ms/step - loss: 0.1342 - accuracy: 0.9492 - val_loss: 0.1231 - val_accuracy: 0.9551\n",
            "Epoch 105/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1103 - accuracy: 0.9566 - val_loss: 0.1198 - val_accuracy: 0.9548\n",
            "Epoch 106/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1062 - accuracy: 0.9618 - val_loss: 0.1234 - val_accuracy: 0.9532\n",
            "Epoch 107/160\n",
            "50/50 [==============================] - 36s 725ms/step - loss: 0.1239 - accuracy: 0.9528 - val_loss: 0.1443 - val_accuracy: 0.9467\n",
            "Epoch 108/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1227 - accuracy: 0.9550 - val_loss: 0.1307 - val_accuracy: 0.9515\n",
            "Epoch 109/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1208 - accuracy: 0.9516 - val_loss: 0.1251 - val_accuracy: 0.9544\n",
            "Epoch 110/160\n",
            "50/50 [==============================] - 36s 727ms/step - loss: 0.1167 - accuracy: 0.9574 - val_loss: 0.1244 - val_accuracy: 0.9538\n",
            "Epoch 111/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1339 - accuracy: 0.9510 - val_loss: 0.1311 - val_accuracy: 0.9517\n",
            "Epoch 112/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1299 - accuracy: 0.9490 - val_loss: 0.1193 - val_accuracy: 0.9545\n",
            "Epoch 113/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1337 - accuracy: 0.9518 - val_loss: 0.1352 - val_accuracy: 0.9486\n",
            "Epoch 114/160\n",
            "50/50 [==============================] - 37s 734ms/step - loss: 0.1170 - accuracy: 0.9568 - val_loss: 0.1197 - val_accuracy: 0.9544\n",
            "Epoch 115/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1175 - accuracy: 0.9545 - val_loss: 0.1264 - val_accuracy: 0.9518\n",
            "Epoch 116/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1252 - accuracy: 0.9528 - val_loss: 0.1494 - val_accuracy: 0.9459\n",
            "Epoch 117/160\n",
            "50/50 [==============================] - 36s 730ms/step - loss: 0.1294 - accuracy: 0.9508 - val_loss: 0.1265 - val_accuracy: 0.9534\n",
            "Epoch 118/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1303 - accuracy: 0.9520 - val_loss: 0.1378 - val_accuracy: 0.9487\n",
            "Epoch 119/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1255 - accuracy: 0.9502 - val_loss: 0.1185 - val_accuracy: 0.9552\n",
            "Epoch 120/160\n",
            "50/50 [==============================] - 37s 735ms/step - loss: 0.1194 - accuracy: 0.9586 - val_loss: 0.1224 - val_accuracy: 0.9539\n",
            "Epoch 121/160\n",
            "50/50 [==============================] - 37s 745ms/step - loss: 0.1151 - accuracy: 0.9548 - val_loss: 0.1187 - val_accuracy: 0.9545\n",
            "Epoch 122/160\n",
            "50/50 [==============================] - 37s 735ms/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 0.1282 - val_accuracy: 0.9530\n",
            "Epoch 123/160\n",
            "50/50 [==============================] - 37s 734ms/step - loss: 0.1342 - accuracy: 0.9474 - val_loss: 0.1209 - val_accuracy: 0.9542\n",
            "Epoch 124/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.1286 - accuracy: 0.9512 - val_loss: 0.1320 - val_accuracy: 0.9500\n",
            "Epoch 125/160\n",
            "50/50 [==============================] - 36s 730ms/step - loss: 0.1416 - accuracy: 0.9476 - val_loss: 0.1834 - val_accuracy: 0.9326\n",
            "Epoch 126/160\n",
            "50/50 [==============================] - 37s 735ms/step - loss: 0.1287 - accuracy: 0.9488 - val_loss: 0.1233 - val_accuracy: 0.9535\n",
            "Epoch 127/160\n",
            "29/50 [================>.............] - ETA: 8s - loss: 0.1152 - accuracy: 0.9569Using an offset of  1  before striding\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1191 - accuracy: 0.9558 - val_loss: 0.1226 - val_accuracy: 0.9541\n",
            "Epoch 128/160\n",
            "50/50 [==============================] - 36s 726ms/step - loss: 0.1199 - accuracy: 0.9567 - val_loss: 0.1190 - val_accuracy: 0.9562\n",
            "Epoch 129/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.1165 - accuracy: 0.9556 - val_loss: 0.1230 - val_accuracy: 0.9548\n",
            "Epoch 130/160\n",
            "50/50 [==============================] - 36s 730ms/step - loss: 0.1040 - accuracy: 0.9622 - val_loss: 0.1224 - val_accuracy: 0.9540\n",
            "Epoch 131/160\n",
            "50/50 [==============================] - 37s 734ms/step - loss: 0.1314 - accuracy: 0.9502 - val_loss: 0.1249 - val_accuracy: 0.9546\n",
            "Epoch 132/160\n",
            "50/50 [==============================] - 37s 736ms/step - loss: 0.1141 - accuracy: 0.9588 - val_loss: 0.1280 - val_accuracy: 0.9525\n",
            "Epoch 133/160\n",
            "50/50 [==============================] - 37s 735ms/step - loss: 0.1224 - accuracy: 0.9518 - val_loss: 0.1206 - val_accuracy: 0.9561\n",
            "Epoch 134/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1100 - accuracy: 0.9588 - val_loss: 0.1237 - val_accuracy: 0.9536\n",
            "Epoch 135/160\n",
            "50/50 [==============================] - 37s 736ms/step - loss: 0.1142 - accuracy: 0.9544 - val_loss: 0.1156 - val_accuracy: 0.9571\n",
            "Epoch 136/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1119 - accuracy: 0.9554 - val_loss: 0.1229 - val_accuracy: 0.9550\n",
            "Epoch 137/160\n",
            "50/50 [==============================] - 37s 737ms/step - loss: 0.1081 - accuracy: 0.9582 - val_loss: 0.1487 - val_accuracy: 0.9446\n",
            "Epoch 138/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1185 - accuracy: 0.9566 - val_loss: 0.1703 - val_accuracy: 0.9372\n",
            "Epoch 139/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1206 - accuracy: 0.9562 - val_loss: 0.1180 - val_accuracy: 0.9555\n",
            "Epoch 140/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1178 - accuracy: 0.9554 - val_loss: 0.1206 - val_accuracy: 0.9555\n",
            "Epoch 141/160\n",
            "50/50 [==============================] - 36s 729ms/step - loss: 0.1160 - accuracy: 0.9558 - val_loss: 0.1402 - val_accuracy: 0.9485\n",
            "Epoch 142/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1103 - accuracy: 0.9564 - val_loss: 0.1181 - val_accuracy: 0.9551\n",
            "Epoch 143/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1256 - accuracy: 0.9496 - val_loss: 0.1243 - val_accuracy: 0.9536\n",
            "Epoch 144/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1262 - accuracy: 0.9516 - val_loss: 0.1371 - val_accuracy: 0.9471\n",
            "Epoch 145/160\n",
            "50/50 [==============================] - 37s 734ms/step - loss: 0.1129 - accuracy: 0.9576 - val_loss: 0.1243 - val_accuracy: 0.9536\n",
            "Epoch 146/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1366 - accuracy: 0.9486 - val_loss: 0.1311 - val_accuracy: 0.9513\n",
            "Epoch 147/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.1068 - accuracy: 0.9600 - val_loss: 0.1473 - val_accuracy: 0.9457\n",
            "Epoch 148/160\n",
            "50/50 [==============================] - 37s 732ms/step - loss: 0.1302 - accuracy: 0.9476 - val_loss: 0.1177 - val_accuracy: 0.9562\n",
            "Epoch 149/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1151 - accuracy: 0.9570 - val_loss: 0.1171 - val_accuracy: 0.9561\n",
            "Epoch 150/160\n",
            "50/50 [==============================] - 37s 731ms/step - loss: 0.1271 - accuracy: 0.9494 - val_loss: 0.1158 - val_accuracy: 0.9574\n",
            "Epoch 151/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1204 - accuracy: 0.9572 - val_loss: 0.1241 - val_accuracy: 0.9539\n",
            "Epoch 152/160\n",
            "45/50 [==========================>...] - ETA: 2s - loss: 0.1201 - accuracy: 0.9564Using an offset of  0  before striding\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1207 - accuracy: 0.9568 - val_loss: 0.1218 - val_accuracy: 0.9542\n",
            "Epoch 153/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1005 - accuracy: 0.9634 - val_loss: 0.1174 - val_accuracy: 0.9567\n",
            "Epoch 154/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1121 - accuracy: 0.9580 - val_loss: 0.1203 - val_accuracy: 0.9560\n",
            "Epoch 155/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1165 - accuracy: 0.9552 - val_loss: 0.1230 - val_accuracy: 0.9547\n",
            "Epoch 156/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1037 - accuracy: 0.9612 - val_loss: 0.1178 - val_accuracy: 0.9555\n",
            "Epoch 157/160\n",
            "50/50 [==============================] - 37s 733ms/step - loss: 0.1072 - accuracy: 0.9582 - val_loss: 0.1430 - val_accuracy: 0.9453\n",
            "Epoch 158/160\n",
            "50/50 [==============================] - 37s 730ms/step - loss: 0.1193 - accuracy: 0.9540 - val_loss: 0.1563 - val_accuracy: 0.9418\n",
            "Epoch 159/160\n",
            "50/50 [==============================] - 36s 730ms/step - loss: 0.1152 - accuracy: 0.9551 - val_loss: 0.1158 - val_accuracy: 0.9570\n",
            "Epoch 160/160\n",
            "50/50 [==============================] - 36s 728ms/step - loss: 0.1139 - accuracy: 0.9564 - val_loss: 0.1287 - val_accuracy: 0.9541\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7cxXBrcMX3F",
        "outputId": "5c17689d-1fc1-4e3d-93de-37324aaebdd9"
      },
      "source": [
        "model.set_weights(auroc_callback.best_weights)\n",
        "print(\"Validation set AUROC with best-loss early stopping:\",\n",
        "      roc_auc_score(y_true=valid_data.Y, y_score=model.predict(valid_data.X)))\n",
        "print(\"Test set AUROC with best-loss early stopping:\",    \n",
        "      roc_auc_score(y_true=test_data.Y, y_score=model.predict(test_data.X)))\n",
        "model.set_weights(auroc_callback.best_weights) \n",
        "print(\"Validation AUROC at best-auroc early stopping:\",\n",
        "      roc_auc_score(y_true=valid_data.Y, y_score=model.predict(valid_data.X)))\n",
        "print(\"Test set AUROC at best-auroc early stopping:\",\n",
        "      roc_auc_score(y_true=test_data.Y, y_score=model.predict(test_data.X)))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation set AUROC with best-loss early stopping: 0.9883717643873173\n",
            "Test set AUROC with best-loss early stopping: 0.9892211739378929\n",
            "Validation AUROC at best-auroc early stopping: 0.9883717643873173\n",
            "Test set AUROC at best-auroc early stopping: 0.9892211739378929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p8EmiCOvfPF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}